# This robots.txt file is used to disallow robots to crawl our staging environment alpha.ec2-18-224-212-70.us-east-2.compute.amazonaws.com, which has the same content as the main site
User-agent: *
Disallow: /
